{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07639119",
   "metadata": {},
   "source": [
    "About the dataset:\n",
    "\n",
    "1. id: unique id for a news article\n",
    "2. Title: the title of a news article\n",
    "3. Author: author of the news article\n",
    "4. Text: the text of the article; could be incomplete\n",
    "5. label: a label that marks whether the news article is real or fake:\n",
    "\n",
    "1: Fake news\n",
    "\n",
    "0: real news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba11a9c",
   "metadata": {},
   "source": [
    "nltk --->Natural language tool kit\n",
    "stemming takes the word and removes the head and tail so it makes world easier\n",
    "TfidfVectorizer--> convert the functions into feature vector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4e8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Hyper parameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Accuracy score\n",
    "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2d9eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manoj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a668bb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))\n",
    "#These are the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef54e4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title           author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...    Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  Daniel J. Flynn   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data  Preprocessing\n",
    "\n",
    "news_df = pd.read_csv(r'G:\\Data analyst by Shashank\\Project DATA_SETS\\news_train.csv')\n",
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e635cfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff690bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().sum()\n",
    "#Checking the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d62b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the null values with impty strings\n",
    "\n",
    "news_df = news_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets merge the title and author column as content\n",
    "\n",
    "news_df['content'] = news_df['author'] +' ' + news_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23845e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                             content  \n",
       "0  Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
       "1  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
       "2  Consortiumnews.com Why the Truth Might Get You...  \n",
       "3  Jessica Purkiss 15 Civilians Killed In Single ...  \n",
       "4  Howard Portnoy Iranian woman jailed for fictio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d76be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can drop the non required columns or we can select a specific column which we \n",
    "# wanted to build model\n",
    "\n",
    "x= news_df.drop(['label','id'], axis=1)\n",
    "y = news_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de5283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 4)\n",
      "(20800,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cfb593",
   "metadata": {},
   "source": [
    "#Lets do the stemming\n",
    "stemming is the process of reducing a word to it's root word\n",
    "\n",
    "eg: actor, actress, acting \n",
    "we get after stemming -->act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badc9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e988fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ', content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50d23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['content'] = news_df['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626c152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the data and label since we want only the content not values \n",
    "x = news_df['content']\n",
    "y = news_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f55a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800,)\n",
      "(20800,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c891673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since computer cannot understand the text we convert content text into number\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f48890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 17128)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed83dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16640, 17128)\n",
      "(16640,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into training and test data\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=3)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bd9727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "pipe = make_pipeline(StandardScaler(with_mean=False),LogisticRegression())\n",
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a8ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingData Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "\n",
    "#Accuracy score on training data\n",
    "x_train_predict = pipe.predict(x_train)\n",
    "training_data_accuracy = accuracy_score(x_train_predict,y_train)\n",
    "print(f'TrainingData Accuracy : {training_data_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cedb5b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy : 0.9860576923076924\n",
      "Confusion matrix:[[2051   32]\n",
      " [  26 2051]]\n",
      "Classification report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2083\n",
      "           1       0.98      0.99      0.99      2077\n",
      "\n",
      "    accuracy                           0.99      4160\n",
      "   macro avg       0.99      0.99      0.99      4160\n",
      "weighted avg       0.99      0.99      0.99      4160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing score on test data\n",
    "x_test_predict = pipe.predict(x_test)\n",
    "test_data_accuracy = accuracy_score(x_test_predict,y_test)\n",
    "print(f'Test Data Accuracy : {test_data_accuracy}')\n",
    "print(f'Confusion matrix:{confusion_matrix(x_test_predict,y_test)}')\n",
    "print(f'Classification report :{classification_report(x_test_predict,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b765b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "model.append(LogisticRegression())\n",
    "model.append(DecisionTreeClassifier())\n",
    "model.append(SVC())\n",
    "model.append(RandomForestClassifier())\n",
    "model.append(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d9020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(model):\n",
    "    for x in range(len(model)):\n",
    "        model[x].fit(x_train,y_train)\n",
    "        x_train_predict = model[x].predict(x_train)\n",
    "        training_accuracy = accuracy_score(x_train_predict,y_train)\n",
    "        print(f'Training accuracy of {model[x]} is:{training_accuracy}')\n",
    "        x_test_predict = model[x].predict(x_test)\n",
    "        test_accuracy = accuracy_score(x_test_predict, y_test)\n",
    "        print(f'Testing accuracy of {model[x]} is:{test_accuracy}')\n",
    "        print('*'*30)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62cae224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of LogisticRegression() is:0.9861778846153846\n",
      "Testing accuracy of LogisticRegression() is:0.9764423076923077\n",
      "******************************\n",
      "Training accuracy of DecisionTreeClassifier() is:1.0\n",
      "Testing accuracy of DecisionTreeClassifier() is:0.9939903846153846\n",
      "******************************\n",
      "Training accuracy of SVC() is:0.9990384615384615\n",
      "Testing accuracy of SVC() is:0.9918269230769231\n",
      "******************************\n",
      "Training accuracy of RandomForestClassifier() is:1.0\n",
      "Testing accuracy of RandomForestClassifier() is:0.9930288461538461\n",
      "******************************\n",
      "Training accuracy of KNeighborsClassifier() is:0.5357572115384616\n",
      "Testing accuracy of KNeighborsClassifier() is:0.5271634615384615\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "testing_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12a0b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing cross_val_score\n",
    "#I am using stratified k fold since we are using Classification problem\n",
    "\n",
    "def cross_val_scoring(model):\n",
    "    for x in range(len(model)):\n",
    "        skf=StratifiedKFold(n_splits=3)\n",
    "        cross_val =cross_val_score(estimator=model[x],X=X, y=y,cv=skf)\n",
    "        print(f' {model[x]} cross_val_score accuracy is :{np.mean(cross_val)}')\n",
    "        print('*'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6332d5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LogisticRegression() cross_val_score accuracy is :0.9742307783567671\n",
      "******************************\n",
      " DecisionTreeClassifier() cross_val_score accuracy is :0.991057720001709\n",
      "******************************\n",
      " SVC() cross_val_score accuracy is :0.9871635169498302\n",
      "******************************\n",
      " RandomForestClassifier() cross_val_score accuracy is :0.992067376994021\n",
      "******************************\n",
      " KNeighborsClassifier() cross_val_score accuracy is :0.5204325514140987\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "cross_val_scoring(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c0c2d",
   "metadata": {},
   "source": [
    "******************Yaaaaaa*******************\n",
    "Random Forest works best but it's slow :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
