{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846b1a03",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdfac1",
   "metadata": {},
   "source": [
    "#### Basic Text Preprocessing:\n",
    "1. Lower casing\n",
    "2. Remove HTML Tags\n",
    "3. Remove Punctuations.\n",
    "4. Chat word treatment.\n",
    "5. Spelling correction.\n",
    "6. Removing Stop words.\n",
    "7. Handeling Emojis.\n",
    "8. Tokenization\n",
    "9. Stemming.\n",
    "10. Lematization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1674597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59530c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'review':['Hi My Name Is Manoj ND','<CENTER>This will center your contents</CENTER>']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffbf6268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi my name is manoj nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;center&gt;this will center your contents&lt;/center&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review\n",
       "0                           hi my name is manoj nd\n",
       "1  <center>this will center your contents</center>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### LOwercasing\n",
    "\n",
    "df['review'] = df['review'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d98d754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove HTML Tags and Removing URLs by using Regular Expression\n",
    "\n",
    "#We use Regular expression and remove it.\n",
    "\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(\"(?i)<td[^>]*>\", \" \")\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39eaf68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec07b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd723fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Punctuation\n",
    "\n",
    "#'!\"#$%\\\"'()+,.|/?@   are punctuations\n",
    "\n",
    "import string\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "512f83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,\" \")\n",
    "    return text\n",
    "\n",
    "#This is very slow when we have more data sets so we use the below\n",
    "\n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['treat'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e6d3b",
   "metadata": {},
   "source": [
    "##### Chat word treatments\n",
    "\n",
    "eg: rm, asap, gn etc...\n",
    "    \n",
    "we want to convert into remove, as soon as possible, good night\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fc5b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either prepare the punction word full form or we can find in online source\n",
    "#We create chat_words --> Is a dictionary which stores word short form and full form\n",
    "\n",
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for a in text.split():\n",
    "        if a.upper() in chat_words:\n",
    "            new_text.append(chat_words[a.upper()])\n",
    "        else:\n",
    "            new_text.append(a)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68561717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certin conditins during several genration are modfied in the same error\n",
      "The corrected one is below ----->\n",
      "Certain conditions during several generation are modified in the same error\n"
     ]
    }
   ],
   "source": [
    "#### Spelling correction\n",
    "#We can use textblob, or NLTK or many others\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "incorrect_text = 'Certin conditins during several genration are modfied in the same error'\n",
    "textblob =  TextBlob(incorrect_text)\n",
    "result  = textblob.correct()\n",
    "print(textblob)\n",
    "print('The corrected one is below ----->')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c27884e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Certin conditins during several genration are modfied in the same error\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "351ffec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Removing Stop Words.\n",
    "#eg: a, the, of, are, my etc...\n",
    "###We use NLTK.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8237e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d22f3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         hi  name  manoj nd\n",
       "1    <center>this  center  contents</center>\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Handling Emojis\n",
    "\n",
    "# 1. Remove the Emojis 2.Replace with the meaning of the emojis\n",
    "\n",
    "#Remove emoji by regular expression\n",
    "import remove_emoji(text):\n",
    "    emoki_pattern = re.compile(\"[Patterns of the emojie]\")\n",
    "    \n",
    "    return emoji.pattern.sub(r'', text)\n",
    "\n",
    "# Replace with the meaning of the emojis\n",
    "import emoji\n",
    "emoji.demojize\n",
    "\n",
    "#We can use this to replace emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83092835",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "##### Converting the text into token.\n",
    "#### We need to check the below 4 things\n",
    "1. Prefix eg: (\" \")\n",
    "2. Suffix eg km).?!\n",
    "3. Infix eg: - --/ ...\n",
    "4. Exception. eg: let's u.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d00593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'Delhi']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I am going to Delhi', ' I will stay in my friends house']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to be very carefull in tokenization\n",
    "####1. Using split function\n",
    "\n",
    "sent1 = 'I am going to Delhi'\n",
    "sent1.split()\n",
    "print(sent1.split())\n",
    "######\n",
    "\n",
    "sent2 = 'I am going to Delhi. I will stay in my friends house'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305501ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Best way to tokinization\n",
    "\n",
    "##NLTK\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "word_tokenize(sent1)\n",
    "\n",
    "### Spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc1 = nlp(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1232dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stemming : It's a process of reducing reducing inflextion in words to their root forms such as mapping a group of words to \n",
    "##same stem even if the stem itself is not a valid word in the language :)\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5132ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_word(text):\n",
    "    return \" \".join([ps.stem[word] for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73dee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Lemmatization: It reduces the inflexted words properly ensuring that the root word belongs to the language.\n",
    "## Lemma : A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words.bbb\n",
    "#Stemming if faster then Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf3f70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61969972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218fcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bfaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
